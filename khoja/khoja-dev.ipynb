{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1b9bf1-3a89-4071-9a56-ff4215e5656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª â†’ Ù…ØªØ¨\n",
      "ÙˆØ§Ù„Ù…Ø¯Ø±Ø³ÙˆÙ† â†’ Ù…Ø±Ø³\n",
      "Ø§Ù„Ø§Ø³ØªØºÙØ§Ø± â†’ ØªÙØ±\n",
      "Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ÙŠÙ† â†’ Ù‡Ø¯Ø³\n",
      "Ø§Ù„Ø·Ø§Ù„Ø¨Ø§Øª â†’ Ø·Ù„Ø¨\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 1ï¸âƒ£ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„\n",
    "def remove_diacritics(text):\n",
    "    arabic_diacritics = re.compile(r\"\"\"\n",
    "        Ù‘ | Ù | Ù‹ | Ù | ÙŒ | Ù | Ù | Ù’\n",
    "    \"\"\", re.VERBOSE)\n",
    "    return re.sub(arabic_diacritics, '', text)\n",
    "\n",
    "\n",
    "# 2ï¸âƒ£ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø­Ø±ÙˆÙ\n",
    "def normalize_arabic(word):\n",
    "    word = re.sub(\"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\", word)\n",
    "    word = re.sub(\"Ù‰\", \"ÙŠ\", word)\n",
    "    word = re.sub(\"Ø¤\", \"Ùˆ\", word)\n",
    "    word = re.sub(\"Ø¦\", \"ÙŠ\", word)\n",
    "    word = re.sub(\"Ø©\", \"Ù‡\", word)\n",
    "    return word\n",
    "\n",
    "\n",
    "# 3ï¸âƒ£ Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚ ÙˆØ§Ù„Ù„ÙˆØ§Ø­Ù‚\n",
    "prefixes = [\"ÙˆØ§Ù„\", \"Ø¨Ø§Ù„\", \"ÙƒØ§Ù„\", \"ÙØ§Ù„\", \"Ù„Ù„\", \"Ø§Ù„\", \"Ùˆ\", \"Ù\", \"Ø¨\", \"Ùƒ\", \"Ù„\"]\n",
    "suffixes = [\"Ø§Øª\", \"ÙˆÙ†\", \"ÙŠÙ†\", \"Ø§Ù†\", \"Ù‡\", \"Ù‡Ø§\", \"Ù‡Ù…\", \"Ù†Ø§\", \"ÙŠ\"]\n",
    "\n",
    "\n",
    "def remove_prefix(word):\n",
    "    for p in prefixes:\n",
    "        if word.startswith(p) and len(word) > len(p) + 2:\n",
    "            return word[len(p):]\n",
    "    return word\n",
    "\n",
    "\n",
    "def remove_suffix(word):\n",
    "    for s in suffixes:\n",
    "        if word.endswith(s) and len(word) > len(s) + 2:\n",
    "            return word[:-len(s)]\n",
    "    return word\n",
    "\n",
    "\n",
    "# 4ï¸âƒ£ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„ØµØ±ÙÙŠØ© (Khoja Patterns)\n",
    "patterns = {\n",
    "    \"ÙØ§Ø¹Ù„\": [0, 2, 4],\n",
    "    \"Ù…ÙØ¹Ù„\": [1, 3, 4],\n",
    "    \"ÙØ¹ÙˆÙ„\": [0, 2, 3],\n",
    "    \"ÙØ¹ÙŠÙ„\": [0, 2, 3],\n",
    "    \"Ù…ÙØ¹ÙˆÙ„\": [1, 3, 4],\n",
    "    \"ØªÙØ¹ÙŠÙ„\": [1, 3, 4],\n",
    "    \"Ø§ÙØªØ¹Ø§Ù„\": [1, 3, 5],\n",
    "    \"Ø§Ø³ØªÙØ¹Ø§Ù„\": [2, 4, 6]\n",
    "}\n",
    "\n",
    "\n",
    "# 5ï¸âƒ£ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ø°Ø±\n",
    "def extract_root(word):\n",
    "    for pattern, indexes in patterns.items():\n",
    "        if len(word) == len(pattern):\n",
    "            try:\n",
    "                root = ''.join(word[i] for i in indexes)\n",
    "                return root\n",
    "            except:\n",
    "                pass\n",
    "    return word\n",
    "\n",
    "\n",
    "# 6ï¸âƒ£ Khoja Stemmer Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ\n",
    "def khoja_stemmer(word):\n",
    "    word = remove_diacritics(word)\n",
    "    word = normalize_arabic(word)\n",
    "    word = remove_prefix(word)\n",
    "    word = remove_suffix(word)\n",
    "    return extract_root(word)\n",
    "\n",
    "\n",
    "# ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø±\n",
    "if __name__ == \"__main__\":\n",
    "    words = [\n",
    "        \"Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª\",\n",
    "        \"ÙˆØ§Ù„Ù…Ø¯Ø±Ø³ÙˆÙ†\",\n",
    "        \"Ø§Ù„Ø§Ø³ØªØºÙØ§Ø±\",\n",
    "        \"Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ÙŠÙ†\",\n",
    "        \"Ø§Ù„Ø·Ø§Ù„Ø¨Ø§Øª\"\n",
    "    ]\n",
    "\n",
    "    for w in words:\n",
    "        print(w, \"â†’\", khoja_stemmer(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba738a8-5141-47f1-bedc-cf59a6c2c5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª â†’ Ù…ÙƒØ¨\n",
      "ÙˆØ§Ù„Ù…Ø¯Ø±Ø³ÙˆÙ† â†’ Ù…Ø¯Ø±\n",
      "Ø§Ù„Ø§Ø³ØªØºÙØ§Ø± â†’ Ø§Ø³Øª\n",
      "Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ÙŠÙ† â†’ Ù…Ù‡Ù†\n",
      "Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ â†’ Ù…Ø³Øª\n",
      "Ø§Ù„Ø·Ø§Ù„Ø¨Ø§Øª â†’ Ø·Ù„Ø¨\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ===============================\n",
    "# 1ï¸âƒ£ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„\n",
    "# ===============================\n",
    "def remove_diacritics(text):\n",
    "    return re.sub(r\"[Ù‘ÙÙ‹ÙÙŒÙÙÙ’Ù€]\", \"\", text)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 2ï¸âƒ£ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø­Ø±ÙˆÙ\n",
    "# ===============================\n",
    "def normalize_arabic(word):\n",
    "    substitutions = {\n",
    "        \"Ø£\": \"Ø§\", \"Ø¥\": \"Ø§\", \"Ø¢\": \"Ø§\",\n",
    "        \"Ù‰\": \"ÙŠ\",\n",
    "        \"Ø¤\": \"Ùˆ\",\n",
    "        \"Ø¦\": \"ÙŠ\",\n",
    "        \"Ø©\": \"Ù‡\"\n",
    "    }\n",
    "    for k, v in substitutions.items():\n",
    "        word = word.replace(k, v)\n",
    "    return word\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 3ï¸âƒ£ Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚ ÙˆØ§Ù„Ù„ÙˆØ§Ø­Ù‚\n",
    "# ===============================\n",
    "prefixes = [\"ÙˆØ§Ù„\", \"Ø¨Ø§Ù„\", \"ÙƒØ§Ù„\", \"ÙØ§Ù„\", \"Ù„Ù„\", \"Ø§Ù„\", \"Ùˆ\", \"Ù\", \"Ø¨\", \"Ùƒ\", \"Ù„\", \"Ø³\"]\n",
    "suffixes = [\"Ø§Øª\", \"ÙˆÙ†\", \"ÙŠÙ†\", \"Ø§Ù†\", \"Ù‡Ø§\", \"Ù‡Ù…\", \"Ù†Ø§\", \"ÙŠ\", \"Ù‡\"]\n",
    "\n",
    "internal_letters = [\"Ø§\", \"Øª\", \"Ù…\", \"Ø³\", \"Ù†\", \"ÙŠ\"]\n",
    "\n",
    "\n",
    "def remove_prefixes(word):\n",
    "    for p in prefixes:\n",
    "        if word.startswith(p) and len(word) - len(p) >= 3:\n",
    "            word = word[len(p):]\n",
    "    return word\n",
    "\n",
    "\n",
    "def remove_suffixes(word):\n",
    "    for s in suffixes:\n",
    "        if word.endswith(s) and len(word) - len(s) >= 3:\n",
    "            word = word[:-len(s)]\n",
    "    return word\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 4ï¸âƒ£ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø²ÙˆØ§Ø¦Ø¯ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©\n",
    "# ===============================\n",
    "def remove_internal_letters(word):\n",
    "    if len(word) > 3:\n",
    "        for l in internal_letters:\n",
    "            if l in word[1:-1]:\n",
    "                temp = word.replace(l, \"\", 1)\n",
    "                if len(temp) >= 3:\n",
    "                    return temp\n",
    "    return word\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 5ï¸âƒ£ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¬Ø°Ø±\n",
    "# ===============================\n",
    "def is_valid_root(root):\n",
    "    return len(root) == 3 and root.isalpha()\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 6ï¸âƒ£ Khoja Stemmer Ø§Ù„Ù…Ø­Ø³Ù‘Ù†\n",
    "# ===============================\n",
    "def khoja_stemmer_improved(word):\n",
    "    word = remove_diacritics(word)\n",
    "    word = normalize_arabic(word)\n",
    "\n",
    "    word = remove_prefixes(word)\n",
    "    word = remove_suffixes(word)\n",
    "\n",
    "    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙˆÙ† Ø¥Ø²Ø§Ù„Ø© Ø¯Ø§Ø®Ù„ÙŠØ©\n",
    "    if is_valid_root(word):\n",
    "        return word\n",
    "\n",
    "    # Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø¯Ø§Ø®Ù„ÙŠØ©\n",
    "    word2 = remove_internal_letters(word)\n",
    "    if is_valid_root(word2):\n",
    "        return word2\n",
    "\n",
    "    # Ø¢Ø®Ø± Ø­Ù„: Ø£ÙˆÙ„ 3 Ø£Ø­Ø±Ù\n",
    "    return word[:3]\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø±\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    words = [\n",
    "        \"Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª\",\n",
    "        \"ÙˆØ§Ù„Ù…Ø¯Ø±Ø³ÙˆÙ†\",\n",
    "        \"Ø§Ù„Ø§Ø³ØªØºÙØ§Ø±\",\n",
    "        \"Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ÙŠÙ†\",\n",
    "        \"Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬\",\n",
    "        \"Ø§Ù„Ø·Ø§Ù„Ø¨Ø§Øª\"\n",
    "    ]\n",
    "\n",
    "    for w in words:\n",
    "        print(w, \"â†’\", khoja_stemmer_improved(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b9fd8a-0d06-4867-8836-ce40de6226c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
